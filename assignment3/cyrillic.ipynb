{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that takes a filepath to the folder containing the cyrillic images. Loops through each file, returning\n",
    "# a dataframe with the image data and classification in a pandas dataframe.\n",
    "\n",
    "# TAs: When grading, you can simply pass in the filepath to the folder containing the validation cyrillic images\n",
    "# into this method and it should return a dataframe with the image data appropriately resized and manipulated.\n",
    "# HOWEVER NOTE: This method assumes that the structure of passed-in folder is the same as that of\n",
    "# the folder of cyrillic training data provided. If the folder structure is not the same, then you'll need to write your own for loop\n",
    "# and then use the get_image_data method found below.\n",
    "\n",
    "def build_images_data(cyrillic_path):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for dirName, subdirList, fileNames in os.walk(cyrillic_path):\n",
    "        for i, fileName in enumerate(fileNames):\n",
    "            if fileName.endswith(\".png\"):\n",
    "    #             print \"{n}. {dirName}/{fileName}\".format(n=i, dirName=dirName, fileName=fileName)\n",
    "                img_bitmap = get_image_data(os.path.join(dirName, fileName))\n",
    "                character = dirName.split(\"/\")[-1]\n",
    "                df = df.append(pd.DataFrame([[character, img_bitmap]], columns=['classification', 'imageData']), ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for taking a filepath to the cyrillic png and returning transformed data.\n",
    "# This method returns a flat array of 0s and 1s, according to whether the image was black or white.\n",
    "binarizer = np.vectorize(lambda i: 1 if i > 0 else 0)\n",
    "\n",
    "IMAGE_EDGE_SIZE = 50\n",
    "\n",
    "def get_image_data(filepath):\n",
    "        img = Image.open(filepath)\n",
    "        img = img.resize((IMAGE_EDGE_SIZE, IMAGE_EDGE_SIZE), Image.ANTIALIAS)\n",
    "        bitmap = np.array(img.getdata())\n",
    "        bitmap = bitmap[:,3] # only need the fourth item in the RGB (transparency)\n",
    "        bitmap = binarizer(bitmap) # change bitmap to 1 or 0\n",
    "        img.close()\n",
    "        return bitmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>imageData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Б</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Б</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Б</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Б</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Б</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classification                                          imageData\n",
       "0              Б  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1              Б  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2              Б  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3              Б  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4              Б  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put a Cyrillic folder in the same folder as this file\n",
    "cyrillic_path = \"../Cyrillic\"\n",
    "        \n",
    "df = build_images_data(cyrillic_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.Categorical(df[\"classification\"]).codes\n",
    "x_data = df[\"imageData\"].values\n",
    "\n",
    "UNIQUE_CLASSES = pd.Categorical(df['classification']).unique()\n",
    "N_CLASSES = len(UNIQUE_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFc9JREFUeJzt3X+QVeWd5/H3N9gREEeQHxaCs804VjKJ9iDpcsyaskw0Ks4kmipNSOIOY1lFKjGGWWMWNJVEZ8stZuIYx90NFlsyhRUJUhgXa0N20ATLTMUf6WYQ8ccsJIPSQqCDQiSCE813/7gHbaG7ae693Nt9z/tVRd1zn/vcc773FN2ffp7z40ZmIkkqn/c0uwBJUnMYAJJUUgaAJJWUASBJJWUASFJJGQCSVFIGgCSVlAEgSSV1xACIiKURsSsiNvVpOzkiHo6IzcXjhKI9IuKuiNgSERsjYlaf98wt+m+OiLnH5uNIkoYqjnQlcEScD+wD7s3MM4u2vwNeycxFEbEQmJCZCyLiMuB64DLgz4B/yMw/i4iTgS6gE0igG/hQZr462LYnTZqU7e3tNX1ASSqb7u7uX2fm5CP1O+5IHTLzsYhoP6T5cuCCYnkZ8CiwoGi/Nyup8kREjI+IqUXfhzPzFYCIeBi4FPj+YNtub2+nq6vrSCVKkvqIiBeH0q/aYwCnZOYOgOJxStE+DdjWp19P0TZQuySpSep9EDj6actB2g9fQcS8iOiKiK7e3t66FidJeke1AbCzmNqheNxVtPcAp/XpNx3YPkj7YTJzSWZ2Zmbn5MlHnMKSJFXpiMcABvAQMBdYVDyu7tP+5YhYQeUg8N7M3BER/wT8t4NnCwEXAzdVX7b0jt/97nf09PRw4MCBZpdyzI0ePZrp06fT1tbW7FLUAo4YABHxfSoHcSdFRA/wLSq/+FdGxLXAS8BVRfc1VM4A2gK8DlwDkJmvRMR/BX5e9PubgweEpVr19PRw4okn0t7eTkR/s42tITPZvXs3PT09zJgxo9nlqAUM5Sygzw7w0oX99E3gugHWsxRYelTVSUNw4MCBlv/lDxARTJw4EY+NqV68ElgtodV/+R9Uls+pxjAAJKmkqj0ILA1b7Qt/WNf1bV3054O+vmfPHpYvX86XvvSlo1rvZZddxvLlyxk/fnwt5UlVMwCkGu3Zs4fvfve7hwXAW2+9xahRowZ835o1a6raXs+r+5ld55AbqiOFoUYWA0Cq0cKFC/nFL37BzJkzaWtrY9y4cUydOpUNGzbw3HPPccUVV7Bt2zYOHDjA/PnzmTdvHvDOrU727dvH7Nmz+chHPsLPfvYzpk2bxurVqxkzZkyTP5lanccApBotWrSI008/nQ0bNvDtb3+bp556ittuu43nnnsOgKVLl9Ld3U1XVxd33XUXu3fvPmwdmzdv5rrrruPZZ59l/PjxPPDAA43+GCohRwBSnZ1zzjnvOk//rrvu4sEHHwRg27ZtbN68mYkTJ77rPTNmzGDmzJkAfOhDH2Lr1q0Nq1flZQBIdXbCCSe8vfzoo4/yyCOP8PjjjzN27FguuOCCfq9YPv74499eHjVqFPv3729IrSo3p4CkGp144om89tpr/b62d+9eJkyYwNixY3nhhRd44oknGlydNDBHAGo5jT5TZeLEiZx33nmceeaZjBkzhlNOOeXt1y699FLuvvtuOjo6eN/73se5557b0NqkwRgAUh0sX7683/bjjz+eH/3oR/2+dnCef9KkSWza9PY3rnLjjTfWvT6pP04BSVJJGQCSVFJOAaku6n37haHyylSpeo4AJKmkDABJKikDQJJKymMAaj23nFTn9e0d9OVqbwcNcOeddzJv3jzGjh1bbXVS1RwBSDU6eDvoatx55528/vrrda5IGhpHAFKN+t4O+uMf/zhTpkxh5cqVvPHGG3zqU5/i1ltv5be//S2f/vSn6enp4a233uIb3/gGO3fuZPv27Xz0ox9l0qRJrFu3rtkfRSVjAEg1WrRoEZs2bWLDhg2sXbuWVatW8dRTT5GZfPKTn+Sxxx6jt7eXU089lR/+sHK67N69eznppJO44447WLduHZMmTWryp1AZOQUk1dHatWtZu3YtZ599NrNmzeKFF15g8+bNnHXWWTzyyCMsWLCAn/70p5x0Up2PU0hVcAQg1VFmctNNN/GFL3zhsNe6u7tZs2YNN910ExdffDHf/OY3m1Ch9A5HAFKN+t4O+pJLLmHp0qXs27cPgJdffpldu3axfft2xo4dy9VXX82NN97I+vXrD3uv1GiOANR6jnDaZr31vR307Nmz+dznPseHP/xhAMaNG8f3vvc9tmzZwte+9jXe85730NbWxuLFiwGYN28es2fPZurUqR4EVsMZAFIdHHo76Pnz57/r+emnn84ll1xy2Puuv/56rr/++mNam6rXrHtcQWPuc+UUkCSVlAEgSSVlAEhSSRkAklRSBoAklZQBIEkl5WmgajlnLTurrut7Zu4zdV3fuHHj2LdvH9u3b+crX/kKq1atOqzPBRdcwO23305nZ2ddty315QhAapJTTz2131/+UqPUFAAR8Z8j4tmI2BQR34+I0RExIyKejIjNEXF/RLy36Ht88XxL8Xp7PT6A1GwLFix41/cB3HLLLdx6661ceOGFzJo1i7POOovVq1cf9r6tW7dy5plnArB//37mzJlDR0cHn/nMZ9i/f3/D6ld5VR0AETEN+ArQmZlnAqOAOcDfAt/JzDOAV4Fri7dcC7yamX8MfKfoJ414c+bM4f7773/7+cqVK7nmmmt48MEHWb9+PevWreOrX/0qmTngOhYvXszYsWPZuHEjX//61+nu7m5E6Sq5WqeAjgPGRMRxwFhgB/Ax4OC4dhlwRbF8efGc4vULIyJq3L7UdGefffbbN3x7+umnmTBhAlOnTuXmm2+mo6ODiy66iJdffpmdO3cOuI7HHnuMq6++GoCOjg46OjoaVb5KrOqDwJn5ckTcDrwE7AfWAt3Ansx8s+jWA0wrlqcB24r3vhkRe4GJwK+rreFImnUfj0bcw0PDy5VXXsmqVav41a9+xZw5c7jvvvvo7e2lu7ubtrY22tvbOXDgwKDr8O8hNVotU0ATqPxVPwM4FTgBmN1P14Pj3v7+dx82Jo6IeRHRFRFdvb291ZYnNdScOXNYsWIFq1at4sorr2Tv3r1MmTKFtrY21q1bx4svvjjo+88//3zuu+8+ADZt2sTGjRsbUbZKrpbTQC8C/i0zewEi4gfAfwTGR8RxxShgOrC96N8DnAb0FFNGJwGvHLrSzFwCLAHo7OwceNJUGkC9T9scig9+8IO89tprTJs2jalTp/L5z3+eT3ziE3R2djJz5kze//73D/r+L37xi1xzzTV0dHQwc+ZMzjnnnAZVrjKrJQBeAs6NiLFUpoAuBLqAdcCVwApgLnDw9IeHiuePF6//JAc7KiaNMM88807wTJo0iccff7zffge/LKa9vZ1NmzYBMGbMGFasWHHsi5T6qHoKKDOfpHIwdz3wTLGuJcAC4IaI2EJljv+e4i33ABOL9huAhTXULUmqUU1XAmfmt4BvHdL8S+Cw8WtmHgCuqmV7kqT68UpgtYSyzCZmJnn4uRNSVQwAjXijR49m9+7dLR8Cmcnu3bt5cc/vml2KWoQ3g9OIN336dHp6eijDacOjR4/mvz/5arPLUIswADTitbW1MWPGjGaX0TC/eeO5ZpegFuEUkCSVlAEgSSVlAEhSSRkAklRSHgSWqtSsu81K9eIIQJJKyhHAMeD3EEgaCRwBSFJJGQCSVFJOAWlE80CsVD1HAJJUUgaAJJWUASBJJWUASFJJGQCSVFIGgCSVlAEgSSVlAEhSSRkAklRSBoAklZQBIEklZQBIUkkZAJJUUgaAJJWUASBJJWUASFJJ+YUwkobM77tuLY4AJKmkHAG0EL8eUdLRcAQgSSVVUwBExPiIWBURL0TE8xHx4Yg4OSIejojNxeOEom9ExF0RsSUiNkbErPp8BElSNWodAfwD8H8z8/3AnwLPAwuBH2fmGcCPi+cAs4Ezin/zgMU1bluSVIOqAyAi/gA4H7gHIDP/PTP3AJcDy4puy4AriuXLgXuz4glgfERMrbpySVJNajkI/EdAL/CPEfGnQDcwHzglM3cAZOaOiJhS9J8GbOvz/p6ibUcNNUgqAU9wODZqmQI6DpgFLM7Ms4Hf8s50T3+in7Y8rFPEvIjoioiu3t7eGsqTJA2mlgDoAXoy88ni+SoqgbDz4NRO8birT//T+rx/OrD90JVm5pLM7MzMzsmTJ9dQniRpMFUHQGb+CtgWEe8rmi4EngMeAuYWbXOB1cXyQ8BfFmcDnQvsPThVJElqvFovBLseuC8i3gv8EriGSqisjIhrgZeAq4q+a4DLgC3A60VfSUdp6+jPNW3b7QeWN23bqr+aAiAzNwCd/bx0YT99E7iulu1JkurHK4ElqaQMAEkqKQNAkkrKAJCkkjIAJKmkDABJKikDQJJKygCQpJIyACSppPxOYEkaQDNvuwF7j/kWHAFIUkk5AlBdNOsvJW9OJlXPEYAklZQBIEklZQBIUkkZAJJUUi19ENgDk5I0MEcAklRSBoAklZQBIEklZQBIUkkZAJJUUgaAJJWUASBJJWUASFJJGQCSVFItfSWwWl8zv7DDK7410jkCkKSSMgAkqaQMAEkqKQNAkkrKg8BSlZp5AFqqB0cAklRSjgCOAb+IRtJIUPMIICJGRcS/RMT/KZ7PiIgnI2JzRNwfEe8t2o8vnm8pXm+vdduSpOrVYwQwH3ge+IPi+d8C38nMFRFxN3AtsLh4fDUz/zgi5hT9PlOH7UtqEEe3raWmAIiI6cCfA7cBN0REAB8DDv4vWQbcQiUALi+WAVYB/yMiIjOzlhqksjlrxh82bdvP/NtLTdmuB9yPjVqngO4E/gvw++L5RGBPZr5ZPO8BphXL04BtAMXre4v+kqQmqDoAIuIvgF2Z2d23uZ+uOYTX+q53XkR0RURXb29vteVJko6glimg84BPRsRlwGgqxwDuBMZHxHHFX/nTge1F/x7gNKAnIo4DTgJeOXSlmbkEWALQ2dnp9JCkpmnqdFsDtlH1CCAzb8rM6ZnZDswBfpKZnwfWAVcW3eYCq4vlh4rnFK//xPl/SWqeY3Eh2AIqB4S3UJnjv6dovweYWLTfACw8BtuWJA1RXS4Ey8xHgUeL5V8C5/TT5wBwVT22J0mqnVcCtxBPlZN0NLwXkCSVlAEgSSXlFJDqolmnyzXrylSpFTgCkKSSMgAkqaQMAEkqKQNAkkqqpQ8Ce2BSkgbmCECSSsoAkKSSMgAkqaQMAEkqqZY+CNwsHnyWNBIYAFKVmvltUVI9GACShj3D9tjwGIAklZQjAElD5l/ircURgCSVlAEgSSVlAEhSSXkMQCOac9JS9RwBSFJJGQCSVFIGgCSVlAEgSSVlAEhSSRkAklRSBoAklZQBIEkl5YVgLcSLoiQdDUcAklRSBoAklZQBIEklVXUARMRpEbEuIp6PiGcjYn7RfnJEPBwRm4vHCUV7RMRdEbElIjZGxKx6fQhJ0tGrZQTwJvDVzPwT4Fzguoj4ALAQ+HFmngH8uHgOMBs4o/g3D1hcw7YlSTWqOgAyc0dmri+WXwOeB6YBlwPLim7LgCuK5cuBe7PiCWB8REytunJJUk3qcgwgItqBs4EngVMycwdUQgKYUnSbBmzr87aeok2S1AQ1B0BEjAMeAP46M38zWNd+2rKf9c2LiK6I6Ort7a21PEnSAGoKgIhoo/LL/77M/EHRvPPg1E7xuKto7wFO6/P26cD2Q9eZmUsyszMzOydPnlxLeZKkQdRyFlAA9wDPZ+YdfV56CJhbLM8FVvdp/8vibKBzgb0Hp4okSY1Xy60gzgP+E/BMRGwo2m4GFgErI+Ja4CXgquK1NcBlwBbgdeCaGrYtSapR1QGQmf9M//P6ABf20z+B66rdniSpvrwSWJJKygCQpJIyACSppAwASSopA0CSSsoAkKSSMgAkqaQMAEkqKQNAkkrKAJCkkjIAJKmkDABJKikDQJJKygCQpJIyACSppAwASSopA0CSSsoAkKSSMgAkqaQMAEkqKQNAkkrKAJCkkjIAJKmkDABJKikDQJJKygCQpJIyACSppAwASSopA0CSSsoAkKSSMgAkqaQMAEkqKQNAkkrKAJCkkmp4AETEpRHxrxGxJSIWNnr7kqSKhgZARIwC/icwG/gA8NmI+EAja5AkVTR6BHAOsCUzf5mZ/w6sAC5vcA2SJBofANOAbX2e9xRtkqQGO67B24t+2vJdHSLmAfOKp/si4l9r2N4k4Nc1vL9ZrLuxrLuxrHsI4q/6+3U5ZP9hKJ0aHQA9wGl9nk8HtvftkJlLgCX12FhEdGVmZz3W1UjW3VjW3VjWPXw0egro58AZETEjIt4LzAEeanANkiQaPALIzDcj4svAPwGjgKWZ+Wwja5AkVTR6CojMXAOsadDm6jKV1ATW3VjW3VjWPUxEZh65lySp5XgrCEkqqZYMgJF6u4mI2BoRz0TEhojoanY9g4mIpRGxKyI29Wk7OSIejojNxeOEZtbYnwHqviUiXi72+4aIuKyZNR4qIk6LiHUR8XxEPBsR84v2Yb2/B6l7WO9vgIgYHRFPRcTTRe23Fu0zIuLJYp/fX5zMMmK13BRQcbuJ/wd8nMpppz8HPpuZzzW1sCGIiK1AZ2YO+3OkI+J8YB9wb2aeWbT9HfBKZi4qgndCZi5oZp2HGqDuW4B9mXl7M2sbSERMBaZm5vqIOBHoBq4A/ophvL8HqfvTDOP9DRARAZyQmfsiog34Z2A+cAPwg8xcERF3A09n5uJm1lqLVhwBeLuJBsjMx4BXDmm+HFhWLC+j8sM+rAxQ97CWmTsyc32x/BrwPJUr6If1/h6k7mEvK/YVT9uKfwl8DFhVtA+7fX60WjEARvLtJhJYGxHdxRXRI80pmbkDKj/8wJQm13M0vhwRG4spomE1ldJXRLQDZwNPMoL29yF1wwjY3xExKiI2ALuAh4FfAHsy882iy0j63dKvVgyAI95uYhg7LzNnUblb6nXFdIWOvcXA6cBMYAfw980tp38RMQ54APjrzPxNs+sZqn7qHhH7OzPfysyZVO5YcA7wJ/11a2xV9dWKAXDE200MV5m5vXjcBTxI5T/dSLKzmPc9OP+7q8n1DElm7ix+2H8P/C+G4X4v5qEfAO7LzB8UzcN+f/dX90jY331l5h7gUeBcYHxEHLx+asT8bhlIKwbAiLzdREScUBwoIyJOAC4GNg3+rmHnIWBusTwXWN3EWobs4C/RwqcYZvu9OCB5D/B8Zt7R56Vhvb8Hqnu472+AiJgcEeOL5THARVSOYawDriy6Dbt9frRa7iwggOK0sjt553YTtzW5pCOKiD+i8lc/VK7QXj6c646I7wMXULlD4k7gW8D/BlYCfwi8BFyVmcPqgOsAdV9AZToiga3AFw7OrQ8HEfER4KfAM8Dvi+abqcynD9v9PUjdn2UY72+AiOigcpB3FJU/lFdm5t8UP6crgJOBfwGuzsw3mldpbVoyACRJR9aKU0CSpCEwACSppAwASSopA0CSSsoAkKSSMgAkqaQMAEkqKQNAkkrq/wNzQnjtVG+ltAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y_train)\n",
    "plt.hist(y_test)\n",
    "plt.hist(y_valid)\n",
    "plt.legend([\"train\", \"test\", \"valid\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the y data into an array of 34 items, with 1 for the correct answer\n",
    "\n",
    "import keras.utils as kutils\n",
    "\n",
    "y_train = kutils.to_categorical(y_train, num_classes=N_CLASSES, dtype='int8')\n",
    "y_test  = kutils.to_categorical(y_test,  num_classes=N_CLASSES, dtype='int8')\n",
    "y_valid = kutils.to_categorical(y_valid, num_classes=N_CLASSES, dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "nn = Sequential()\n",
    "\n",
    "Layer1 = Dense(units=100, activation='relu', input_dim=IMAGE_EDGE_SIZE**2)\n",
    "Layer2 = Dense(units=80, activation='relu')\n",
    "Layer3 = Dense(units=50, activation='relu')\n",
    "Layer4 = Dense(units=20, activation='relu')\n",
    "\n",
    "OutputLayer = Dense(units=N_CLASSES, activation='softmax')\n",
    "\n",
    "nn.add(Layer1)\n",
    "nn.add(Layer2)\n",
    "nn.add(Layer3)\n",
    "nn.add(Layer4)\n",
    "\n",
    "nn.add(OutputLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_36_input to have shape (2500,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-4ea9f97ad5b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/mozhu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mozhu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mozhu/anaconda2/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_36_input to have shape (2500,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "nn.fit(x_train, y_train, epochs=20, batch_size=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
